{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **CONVOLUTIONAL NEURAL NETWORK (CNN)**\n",
    "\n",
    "## Problem\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above.\n",
    "You should stop training once you reach that level of accuracy.\n",
    "\n",
    "Hint: It should succeed in less than 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# show figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Load the MNIST dataset from `tf.keras`.\n",
    "\n",
    "**Note**:\n",
    "- For `Conv2D` we need images to have three dimension.\n",
    "- Use `np.expand_dims` along `axis=-1` (last axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# expand dims\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# check shapes\n",
    "print(\"shapes:\")\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check one image\n",
    "idx = 2\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.title(f\"Size: {x_train[idx].shape}\\nLabel: {y_train[idx]}\")\n",
    "plt.axis('off')\n",
    "plt.imshow(x_train[idx].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Normalization**\n",
    "- It allows the NN model to learn all optimal parameters more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "**Note**\n",
    "\n",
    "- Use `'softmax'` activation function in the output layer since the problem is multi-class classification.\n",
    "- Use `'sparse_categorical_crossentropy'` loss since labels are of ordinal category.\n",
    "- Alternatively, you can convert labels to one-hot-encoding, then use `'categorical_crossentropy'` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# input layer\n",
    "input_tensor = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# convolution layers\n",
    "x = Conv2D(16, 3, activation='relu')(input_tensor)\n",
    "x = MaxPool2D()(x)\n",
    "\n",
    "# fully-connected layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# output layer with 'softmax' activation function\n",
    "output_tensor = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "# compile with 'sparse_categorical_crossentropy' loss\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Callback\n",
    "\n",
    "- You can use [pre-defined callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
    "- Or, you can define custom callback to have more control over what happens during the training or prediction.\n",
    "[See more](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note**:\n",
    "- Use `log.get()` to get desired metric to monitor.\n",
    "- The parameter name in `log.get()` should match the metric defined in `model.compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class MonitorAccuracy(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    a custom class of callback\n",
    "    to check accuracy after end of each epoch, and\n",
    "    to stop training when a certain level of accuracy is reached\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stop_accuracy=0.99):\n",
    "        # initiate\n",
    "        super(MonitorAccuracy, self).__init__()\n",
    "        self.stop_accuracy = stop_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # at the end of the epoch, print loss and accuracy\n",
    "        print(f\"Epoch {epoch+1} - loss: {logs.get('loss'):.4f} - acc: {logs.get('acc'):.4f}\")\n",
    "\n",
    "        # if accuracy is greater than the given 'stop_accuracy':\n",
    "        if logs.get('acc') > self.stop_accuracy:\n",
    "            # print the termination message\n",
    "            print(f\"\\nAccuracy reached to {self.stop_accuracy}. So, cancelling training...\")\n",
    "            # stop training\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "monitor_acc = MonitorAccuracy(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# train the model and save the history\n",
    "hist = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    callbacks=[monitor_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plot the loss and accuracy\n",
    "fig = plt.figure()\n",
    "ax1 = fig.gca()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(hist.history['acc'], label='Accuracy', color='r')\n",
    "ax2.plot(hist.history['loss'], label='Loss', color='b')\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy', color='r')\n",
    "ax2.set_ylabel('Loss', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evauation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# figure for displaying the confusion matrix\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.gca()\n",
    "\n",
    "# display the confution matrix\n",
    "cax = ax.matshow(conf_mat, cmap='Blues')\n",
    "\n",
    "# show the values\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    text_color = 'w' if i == j else 'k'\n",
    "    if z < 0.005:\n",
    "        continue\n",
    "    ax.text(j, i, '{:0.2f}'.format(z), ha='center', va='center', c=text_color)\n",
    "\n",
    "# title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# show class names\n",
    "labels = list(range(10))\n",
    "plt.xticks(labels, labels)\n",
    "plt.yticks(labels, labels)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# show grid lines\n",
    "ax.set_xticks(np.arange(-.5, 10, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, 10, 1), minor=True)\n",
    "ax.grid(which='minor', color='k', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Other metrics**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate precision, recall, and f1 score\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pandas data frame for storing the metrics\n",
    "df = pd.DataFrame({\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "})\n",
    "\n",
    "# calculate the mean\n",
    "df.loc['Mean'] = df.mean()\n",
    "\n",
    "# display\n",
    "df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}