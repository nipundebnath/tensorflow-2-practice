{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **CONVOLUTIONAL NEURAL NETWORK (CNN)**\n",
    "\n",
    "## Problem\n",
    "\n",
    "Train a CNN on the [Cats-vs-Dogs dataset]().\n",
    "\n",
    "Note: Dataset is not divided into train-vaidation-test. Needs a lot of pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# show figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Download the datase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats-and-dogs/\n",
      "    MSR-LA - 3467.docx\n",
      "    readme[1].txt\n",
      "    PetImages/\n",
      "        Cat/\n",
      "            0.jpg\n",
      "            1.jpg\n",
      "            10.jpg\n",
      "            ...\n",
      "        Dog/\n",
      "            0.jpg\n",
      "            1.jpg\n",
      "            10.jpg\n",
      "            ...\n"
     ]
    }
   ],
   "source": [
    "data_url = 'https://download.microsoft.com/download/3/E/1/' \\\n",
    "           '3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "save_dir = '../.tmp'\n",
    "name_zip = 'cats-and-dogs.zip'\n",
    "root_dir = f'{save_dir}/cats-and-dogs'\n",
    "\n",
    "# if not already there, download the files\n",
    "if not os.path.exists(root_dir):\n",
    "    # download the dataset\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.system(f\"\"\"wget --no-check-certificate {data_url} -O {save_dir}/{name_zip}\"\"\")\n",
    "\n",
    "    # unzip the file\n",
    "    zip_ref = zipfile.ZipFile(f'{save_dir}/{name_zip}', 'r')\n",
    "    zip_ref.extractall(root_dir)\n",
    "    zip_ref.close()\n",
    "\n",
    "# see the file structure\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    level = root.replace(root_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for i, f in enumerate(files):\n",
    "        print(f'{subindent}{f}')\n",
    "        if i >= 2:\n",
    "            print(f'{subindent}...')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cat images: 12501\n",
      "# dog images: 12501\n"
     ]
    }
   ],
   "source": [
    "# see number of files\n",
    "print('# cat images:', len(os.listdir(f'{root_dir}/PetImages/Cat/')))\n",
    "print('# dog images:', len(os.listdir(f'{root_dir}/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Split the dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory '../.tmp/cats-and-dogs/train/cat' is created\n",
      "directory '../.tmp/cats-and-dogs/train/dog' is created\n",
      "directory '../.tmp/cats-and-dogs/test/cat' is created\n",
      "directory '../.tmp/cats-and-dogs/test/dog' is created\n"
     ]
    }
   ],
   "source": [
    "# create training and testing folders\n",
    "for subset in ['train', 'test']:\n",
    "    for class_name in ['cat', 'dog']:\n",
    "        os.makedirs(f'{root_dir}/{subset}/{class_name}', exist_ok=True)\n",
    "        print(f\"directory '{root_dir}/{subset}/{class_name}' is created\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of '666.jpg' is zero. So, ignored.\n",
      "Size of '11702.jpg' is zero. So, ignored.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dir_source, dir_train, dir_test, split_ratio):\n",
    "    \"\"\"\n",
    "    Reads the files available in 'dir_source'.\n",
    "    Splits it by 'split_ratio' (train to test ratio).\n",
    "    Puts the training and testing files\n",
    "    in 'dir_train' and 'dir_test' folder, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # get all the filenames in source folder\n",
    "    filenames = []  # list of all file names\n",
    "\n",
    "    # read the source files\n",
    "    for fn in os.listdir(dir_source):\n",
    "        filepath = f'{dir_source}/{fn}'\n",
    "        # if file's size >0, append to the list\n",
    "        if os.path.getsize(filepath) > 0:\n",
    "            filenames.append(fn)\n",
    "        else:\n",
    "            print(f\"Size of '{fn}' is zero. So, ignored.\")\n",
    "\n",
    "    # determine the size of training subset\n",
    "    num_train = int(len(filenames) * split_ratio)\n",
    "\n",
    "    # randomly shuffle the file names\n",
    "    np.random.shuffle(filenames)\n",
    "\n",
    "    # training and testing subsets\n",
    "    train_files = filenames[:num_train]\n",
    "    test_files = filenames[num_train:]\n",
    "\n",
    "    # function for copying all files\n",
    "    def copy_all_files(src, dst, file_names):\n",
    "        for file in file_names:\n",
    "            shutil.copy(f'{src}/{file}', f'{dst}/{file}')\n",
    "\n",
    "    # copy training files\n",
    "    copy_all_files(dir_source, dir_train, train_files)\n",
    "    # copy test files\n",
    "    copy_all_files(dir_source, dir_test, test_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.9\n",
    "\n",
    "# split the cat and dog images into training and testing subsets\n",
    "for class_name in ['cat', 'dog']:\n",
    "    # source directory\n",
    "    _dir_source = f'{root_dir}/PetImages/{class_name.capitalize()}'\n",
    "\n",
    "    # train-test directories\n",
    "    _dir_train = f'{root_dir}/train/{class_name}'\n",
    "    _dir_test = f'{root_dir}/test/{class_name}'\n",
    "\n",
    "    # split the dataset\n",
    "    split_dataset(_dir_source, _dir_train, _dir_test, SPLIT_RATIO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# normalizes the input feature\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1 / 255.,\n",
    ")\n",
    "\n",
    "# train data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=root_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# test data generator without shuffling\n",
    "# NOTE: ideally, you should not use training data for testing\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    directory=root_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get name of the classes\n",
    "labels = list(test_generator.class_indices.keys())\n",
    "# capitalize\n",
    "labels = [l.capitalize() for l in labels]\n",
    "# get indices of the classes\n",
    "indices = list(test_generator.class_indices.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get one batch\n",
    "for (batch_images, batch_labesl) in test_generator:\n",
    "    # get one sample\n",
    "    image = batch_images[0]\n",
    "    label = labels[int(batch_labesl[0])]\n",
    "\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    plt.title(f\"Size: {image.shape}\\nLabel: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.show()\n",
    "\n",
    "    break\n",
    "\n",
    "# reset\n",
    "test_generator.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "**Note**\n",
    "- The problem is binary classification.\n",
    "- Use `'sigmoid'` activation function in the output layer.\n",
    "- Use `'binary_crossentropy'` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input layer\n",
    "input_tensor = Input(shape=[150, 150, 3])\n",
    "\n",
    "# convolution layers\n",
    "x = Conv2D(64, 3, activation='relu')(input_tensor)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu')(x)\n",
    "x = MaxPool2D()(x)\n",
    "x = Conv2D(32, 3, activation='relu')(x)\n",
    "x = MaxPool2D()(x)\n",
    "\n",
    "# fully-connected layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# output layer with 'sigmoid' activation function\n",
    "output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "\n",
    "# compile with 'binary_crossentropy' loss\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Callback\n",
    "\n",
    "- You can use [pre-defined callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
    "- Or, you can define custom callback to have more control over what happens during the training or prediction.\n",
    "[See more](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note**:\n",
    "- Use `log.get()` to get desired metric to monitor.\n",
    "- The parameter name in `log.get()` should match the metric defined in `model.compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MonitorAccuracy(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    a custom class of callback\n",
    "    to check accuracy after end of each epoch, and\n",
    "    to stop training when a certain level of accuracy is reached\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stop_accuracy=0.99):\n",
    "        # initiate\n",
    "        super(MonitorAccuracy, self).__init__()\n",
    "        self.stop_accuracy = stop_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # at the end of the epoch, print loss and accuracy\n",
    "        print(f\"Epoch {epoch+1} - loss: {logs.get('loss'):.4f} - acc: {logs.get('acc'):.4f}\")\n",
    "\n",
    "        # if accuracy is greater than the given 'stop_accuracy':\n",
    "        if logs.get('acc') > self.stop_accuracy:\n",
    "            # print the termination message\n",
    "            print(f\"\\nAccuracy reached to {self.stop_accuracy}. So, cancelling training...\")\n",
    "            # stop training\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "monitor_acc = MonitorAccuracy(0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train the model and save the history\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[monitor_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot the loss and accuracy\n",
    "fig = plt.figure()\n",
    "ax1 = fig.gca()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(hist.history['acc'], label='Accuracy', color='r')\n",
    "ax2.plot(hist.history['loss'], label='Loss', color='b')\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy', color='r')\n",
    "ax2.set_ylabel('Loss', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evauation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# NOTE: 'test_generator' uses training data, without shuffling\n",
    "# ideally, you should not use training data for testing\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get true test labels\n",
    "y_test = test_generator.labels\n",
    "\n",
    "# confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# figure for displaying the confusion matrix\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.gca()\n",
    "\n",
    "# display the confution matrix\n",
    "cax = ax.matshow(conf_mat, cmap='Blues')\n",
    "\n",
    "# show the values\n",
    "for (i, j), z in np.ndenumerate(conf_mat):\n",
    "    text_color = 'w' if i == j else 'k'\n",
    "    if z < 0.005:\n",
    "        continue\n",
    "    ax.text(j, i, '{:0.2f}'.format(z), ha='center', va='center', c=text_color)\n",
    "\n",
    "# title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# show class names\n",
    "plt.xticks(indices, labels)\n",
    "plt.yticks(indices, labels)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# show grid lines\n",
    "ax.set_xticks(np.arange(-.5, 2, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, 2, 1), minor=True)\n",
    "ax.grid(which='minor', color='k', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Other metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate precision, recall, and f1 score\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pandas data frame for storing the metrics\n",
    "df = pd.DataFrame({\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "},\n",
    "    index=labels\n",
    ")\n",
    "\n",
    "# calculate the mean\n",
    "df.loc['(Average)'] = df.mean()\n",
    "\n",
    "# display\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf2-plus': conda)",
   "language": "python",
   "name": "python37764bittf2pluscondaab7d8de0804d40f7b6e27d871405ec4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}